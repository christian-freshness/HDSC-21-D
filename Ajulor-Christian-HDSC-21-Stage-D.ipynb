{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rHGixgIrWlM"
   },
   "source": [
    "## Loading Data and Importing of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:59:21.060190Z",
     "iopub.status.busy": "2021-10-13T01:59:21.059755Z",
     "iopub.status.idle": "2021-10-13T01:59:21.066727Z",
     "shell.execute_reply": "2021-10-13T01:59:21.065688Z",
     "shell.execute_reply.started": "2021-10-13T01:59:21.060143Z"
    },
    "id": "gedaDcTgEi08",
    "outputId": "3a0246e2-fe0a-49c5-d28c-3386730173eb"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "#import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKc2viUTFRP9"
   },
   "source": [
    "### importing other necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:59:21.069699Z",
     "iopub.status.busy": "2021-10-13T01:59:21.068857Z",
     "iopub.status.idle": "2021-10-13T01:59:26.327056Z",
     "shell.execute_reply": "2021-10-13T01:59:26.325950Z",
     "shell.execute_reply.started": "2021-10-13T01:59:21.069658Z"
    },
    "id": "GDExQKkBsfWK"
   },
   "outputs": [],
   "source": [
    "import gc # Garbage collector module for memory management\n",
    "from matplotlib import pyplot # For data visualization\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 # OpenCV for image manipulation\n",
    "from tensorflow import keras # We need keras library\n",
    "from tqdm import tqdm # To read in images in batches and see progress\n",
    "from sklearn.model_selection import train_test_split # For the creation of training and validation sets\n",
    "# Define model related parameters\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Input , Dense , Dropout , Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D , BatchNormalization\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint \n",
    "from keras.preprocessing.image import ImageDataGenerator # Used for Data augmentation\n",
    "from keras import backend as K # For specialized and optimized tensor manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:59:26.333124Z",
     "iopub.status.busy": "2021-10-13T01:59:26.332622Z",
     "iopub.status.idle": "2021-10-13T01:59:26.351038Z",
     "shell.execute_reply": "2021-10-13T01:59:26.350090Z",
     "shell.execute_reply.started": "2021-10-13T01:59:26.333083Z"
    },
    "id": "OBsROXjoslkQ"
   },
   "outputs": [],
   "source": [
    "# Defining the fbeta metric\n",
    "def fbeta(y_true, y_pred, threshold_shift=0):\n",
    "    beta = 2\n",
    " \n",
    "    # just in case of hipster activation at the final layer\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    " \n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    " \n",
    "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    " \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    " \n",
    "    beta_squared = beta ** 2\n",
    "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtUHR08ftR5F"
   },
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEeoAYDFbYwb"
   },
   "source": [
    "Let's now perform some EDA on the dataset which involves having a look at the images and reading in the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:59:26.353397Z",
     "iopub.status.busy": "2021-10-13T01:59:26.352754Z",
     "iopub.status.idle": "2021-10-13T01:59:28.280963Z",
     "shell.execute_reply": "2021-10-13T01:59:28.275463Z",
     "shell.execute_reply.started": "2021-10-13T01:59:26.353356Z"
    },
    "id": "AMT3BFbKsrpc",
    "outputId": "4104e5e0-af07-4e34-8f74-1d87bed333e9"
   },
   "outputs": [],
   "source": [
    "# Let's view some images\n",
    "plt.figure(figsize=(20,20))\n",
    "# define location of dataset\n",
    "folder = '../input/planets-dataset/planet/planet/train-jpg/'\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# define filename\n",
    "\tfilename = folder + 'train_' + str(i) + '.jpg'\n",
    "\t# load image pixels\n",
    "\timage = imread(filename)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:59:28.284411Z",
     "iopub.status.busy": "2021-10-13T01:59:28.283991Z",
     "iopub.status.idle": "2021-10-13T01:59:28.416049Z",
     "shell.execute_reply": "2021-10-13T01:59:28.415294Z",
     "shell.execute_reply.started": "2021-10-13T01:59:28.284365Z"
    },
    "id": "MwFD3G8ruVlB",
    "outputId": "f7b616f1-7ada-45f1-e6de-50ee35eb0bfb"
   },
   "outputs": [],
   "source": [
    "# Reading in the training and test csv files\n",
    "df_train_data = pd.read_csv(\"../input/planets-dataset/planet/planet/train_classes.csv\" )\n",
    "df_test_data = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\n",
    "df_train_data.head() # Checking out the first five rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:59:28.419437Z",
     "iopub.status.busy": "2021-10-13T01:59:28.419065Z",
     "iopub.status.idle": "2021-10-13T01:59:28.462020Z",
     "shell.execute_reply": "2021-10-13T01:59:28.461154Z",
     "shell.execute_reply.started": "2021-10-13T01:59:28.419398Z"
    },
    "id": "GYYLBY0KLGUO"
   },
   "outputs": [],
   "source": [
    "# Flatten the 'tags' column of the training dataset into a list\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list (set(flatten([l.split (' ') for l in df_train_data ['tags'].values])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:59:28.463752Z",
     "iopub.status.busy": "2021-10-13T01:59:28.463401Z",
     "iopub.status.idle": "2021-10-13T01:59:28.471201Z",
     "shell.execute_reply": "2021-10-13T01:59:28.470132Z",
     "shell.execute_reply.started": "2021-10-13T01:59:28.463714Z"
    },
    "id": "cyP6mawFwdxZ",
    "outputId": "836f7ac8-2c0f-4830-b15b-2a1a20f73442"
   },
   "outputs": [],
   "source": [
    "# Organizing a label mapping\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:59:28.473274Z",
     "iopub.status.busy": "2021-10-13T01:59:28.472903Z",
     "iopub.status.idle": "2021-10-13T01:59:28.606005Z",
     "shell.execute_reply": "2021-10-13T01:59:28.605132Z",
     "shell.execute_reply.started": "2021-10-13T01:59:28.473236Z"
    },
    "id": "RkDBq5KAEi2F",
    "outputId": "d513ccbc-a51a-407e-98b2-ad2bb1e1d883"
   },
   "outputs": [],
   "source": [
    "gc.collect() # Used frequently to avoid session crashing due to memory exhaustion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhUGbSf3xrQR"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJHohrN3dOg1"
   },
   "source": [
    "In this Part, we preprocess the data so that it can be used to train the model. We reshape and normalize the images, One-hot encode the labels and split our training sets further into training and validation set using train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T01:59:28.608046Z",
     "iopub.status.busy": "2021-10-13T01:59:28.607684Z",
     "iopub.status.idle": "2021-10-13T02:03:30.505951Z",
     "shell.execute_reply": "2021-10-13T02:03:30.504455Z",
     "shell.execute_reply.started": "2021-10-13T01:59:28.608006Z"
    },
    "id": "-tdNQqZMx5VS",
    "outputId": "0f69adf1-1bd5-4ba1-e74b-fabfa903245e"
   },
   "outputs": [],
   "source": [
    "# Reading in the train image dataset\n",
    "x_train= []\n",
    "y_train= []\n",
    "for img, label in tqdm(df_train_data.values, miniters = 1000):\n",
    "  target = np.zeros(17)\n",
    "  \n",
    "  # We create the 17-dimensional binary label vectors i.e One-hot encoding it\n",
    "  for tag in label.split(' '):\n",
    "    target[label_map[tag]]=1\n",
    "  \n",
    "  # Reshaping and assigning to arbitrary variables\n",
    "  x_train.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(img)), (64,64)))\n",
    "  y_train.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:03:30.507650Z",
     "iopub.status.busy": "2021-10-13T02:03:30.507283Z",
     "iopub.status.idle": "2021-10-13T02:03:30.515370Z",
     "shell.execute_reply": "2021-10-13T02:03:30.514058Z",
     "shell.execute_reply.started": "2021-10-13T02:03:30.507612Z"
    },
    "id": "F3-7nYsLAB7l",
    "outputId": "7ee804dc-1dd1-47e7-f862-0505c2f01197"
   },
   "outputs": [],
   "source": [
    "len (x_train) # Prints out 40,479\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:03:30.517750Z",
     "iopub.status.busy": "2021-10-13T02:03:30.517359Z",
     "iopub.status.idle": "2021-10-13T02:03:30.647616Z",
     "shell.execute_reply": "2021-10-13T02:03:30.646461Z",
     "shell.execute_reply.started": "2021-10-13T02:03:30.517712Z"
    },
    "id": "1vM6Lrr4Ei2i",
    "outputId": "dad1567d-adf1-4608-e914-cde139d231c6"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:03:30.649962Z",
     "iopub.status.busy": "2021-10-13T02:03:30.649472Z",
     "iopub.status.idle": "2021-10-13T02:11:13.133227Z",
     "shell.execute_reply": "2021-10-13T02:11:13.132232Z",
     "shell.execute_reply.started": "2021-10-13T02:03:30.649920Z"
    },
    "id": "kLL_ph_ZCVHF",
    "outputId": "937320f8-a2c8-4acd-8376-c6c9ae43af97"
   },
   "outputs": [],
   "source": [
    "# We Read in the test image dataset and merge the test_additional jpg file to give an output of 61191 rows\n",
    "x_test = []\n",
    " \n",
    "for img, label in tqdm(df_test_data[0:40669].values, miniters=1000):\n",
    "    fil = cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(img)), (64, 64))\n",
    "    x_test.append(fil)\n",
    " \n",
    "for img, label in tqdm(df_test_data[40669:].values, miniters=1000):\n",
    "    fil = cv2.resize(cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(img)), (64, 64))\n",
    "    x_test.append(fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:13.136567Z",
     "iopub.status.busy": "2021-10-13T02:11:13.136274Z",
     "iopub.status.idle": "2021-10-13T02:11:13.144527Z",
     "shell.execute_reply": "2021-10-13T02:11:13.143195Z",
     "shell.execute_reply.started": "2021-10-13T02:11:13.136540Z"
    },
    "id": "rziTae6jDsQ2",
    "outputId": "488afb87-8059-4133-b12a-b2abdc8704ce"
   },
   "outputs": [],
   "source": [
    "len (x_test) # prints 61191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:13.146947Z",
     "iopub.status.busy": "2021-10-13T02:11:13.146500Z",
     "iopub.status.idle": "2021-10-13T02:11:13.270122Z",
     "shell.execute_reply": "2021-10-13T02:11:13.269231Z",
     "shell.execute_reply.started": "2021-10-13T02:11:13.146910Z"
    },
    "id": "fK9q2yBrEi3A",
    "outputId": "1d975f2d-eebc-432d-ba65-6e42cd131326"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:13.272161Z",
     "iopub.status.busy": "2021-10-13T02:11:13.271554Z",
     "iopub.status.idle": "2021-10-13T02:11:31.252958Z",
     "shell.execute_reply": "2021-10-13T02:11:31.252045Z",
     "shell.execute_reply.started": "2021-10-13T02:11:13.272123Z"
    },
    "id": "HW3Iex9mGHS3",
    "outputId": "33c43888-9ddb-41d5-f1df-de9e4be93fef"
   },
   "outputs": [],
   "source": [
    "#Change lists to numpy arrays and normalize\n",
    "x_train = np.array(x_train, np.float16)/255.\n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_test = np.array(x_test, np.float16)/255.\n",
    "\n",
    "# Splitting the training dataset into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "# prints  (32383, 64, 64, 3) (32383, 17) (8096, 64, 64, 3) (8096, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:31.254796Z",
     "iopub.status.busy": "2021-10-13T02:11:31.254278Z",
     "iopub.status.idle": "2021-10-13T02:11:31.370618Z",
     "shell.execute_reply": "2021-10-13T02:11:31.369540Z",
     "shell.execute_reply.started": "2021-10-13T02:11:31.254756Z"
    },
    "id": "w0uLxzzxEi3T",
    "outputId": "c9585d5b-8880-4901-b738-49ec64a35e3f"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AOladaUGfkB"
   },
   "source": [
    "# Building Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH9TXUU1kGQv"
   },
   "source": [
    "To tackle this multi-label problem, a combination of a custom deep CNN\n",
    "architecture along with the pre-trained CNN architecture(VGG16) was implemented in Keras with Tensorflow backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1StcTqbkwC_"
   },
   "source": [
    "The custom CNN deep architecture includes a\n",
    "sequence of Convolution-Convolution-Maxpooling (CCM) “super-layers,” each of which are\n",
    "made up of two back-to-back convolutional layers followed by a maximum pooling layer. In\n",
    "these super-layers, each convolutional layer has a ReLu activation function, and a specific\n",
    "number of 3 × 3 filters. The depth of each layer indicates the number of filters applied to\n",
    "it, which increases towards the output of the architecture.\n",
    "The output of the maximum pooling layer, belonging to the last super-layer, is fed to a\n",
    "classification block consisting of a fully connected (FC) layer and an output layer. All 512\n",
    "neurons of the FC layer connect to each of the 17 neurons in the output layer. To bound\n",
    "the neuron values of the FC layer, ReLU activation is applied. The output layer produces\n",
    "prediction probabilities, corresponding to the 17 unique labels, using sigmoid activation.\n",
    "To prevent overfitting, dropout regularization is applied to each CCM super-layer and\n",
    "the FC layer. More specifically, the CMM super-layers have a dropout rate of 0.25, while\n",
    "the fully connected layer has a dropout rate of 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_plE_ypmHzV8"
   },
   "source": [
    "Custom CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:31.372714Z",
     "iopub.status.busy": "2021-10-13T02:11:31.372268Z",
     "iopub.status.idle": "2021-10-13T02:11:33.416705Z",
     "shell.execute_reply": "2021-10-13T02:11:33.415953Z",
     "shell.execute_reply.started": "2021-10-13T02:11:31.372675Z"
    },
    "id": "2kc_f8y2Gknd"
   },
   "outputs": [],
   "source": [
    "input_size = 64\n",
    "input_channels = 3\n",
    " \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(BatchNormalization(input_shape=(input_size, input_size, input_channels)))\n",
    "\n",
    "# CCM_1\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#CCM_2\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "#CCM_3\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "#CCM_4\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Create a feature vector from the CCM_4 final layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected (FC) Layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model .add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(17, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXUbXQIRHikN"
   },
   "source": [
    "Loading Pre-trained CNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEGZQMmQl-9q"
   },
   "source": [
    "To supplement the custom CNN architecture,the pre-trained CNN architecture(VGG16) was implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:33.419727Z",
     "iopub.status.busy": "2021-10-13T02:11:33.419204Z",
     "iopub.status.idle": "2021-10-13T02:11:34.163272Z",
     "shell.execute_reply": "2021-10-13T02:11:34.162435Z",
     "shell.execute_reply.started": "2021-10-13T02:11:33.419686Z"
    },
    "id": "w9-6TVlhEi3n",
    "outputId": "9d74c1d0-df74-4a8e-be0d-50e5aa53e676"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "# Loading the pre-trained VGG16 architecture module\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "\n",
    "# Extract the pre - trained architecture\n",
    "base_model = VGG16(input_shape =(input_size,input_size,3),include_top =False,weights ='imagenet')\n",
    "base_model.summary()\n",
    "\n",
    "# Get the output of the base_model formed above\n",
    "x = base_model.output\n",
    "# Flatten to obtain a feature vector\n",
    "x = Flatten()(x)\n",
    "# Connect the feature vector to to the fully connected (FC) layer\n",
    "x = Dense (512 , activation ='relu')(x)\n",
    "# Form the output label predictions\n",
    "predictions = Dense (17 , activation ='sigmoid')(x)\n",
    "model = Model(inputs= base_model.input,outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:34.165776Z",
     "iopub.status.busy": "2021-10-13T02:11:34.165236Z",
     "iopub.status.idle": "2021-10-13T02:11:34.287128Z",
     "shell.execute_reply": "2021-10-13T02:11:34.286299Z",
     "shell.execute_reply.started": "2021-10-13T02:11:34.165733Z"
    },
    "id": "0e1eTZPKEi3w",
    "outputId": "28872148-06fb-4397-fb83-3d5c40f35191"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PohlXPJOIC4v"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:34.289275Z",
     "iopub.status.busy": "2021-10-13T02:11:34.288789Z",
     "iopub.status.idle": "2021-10-13T02:11:34.298472Z",
     "shell.execute_reply": "2021-10-13T02:11:34.297303Z",
     "shell.execute_reply.started": "2021-10-13T02:11:34.289193Z"
    },
    "id": "jQ3X__Y3m1Py"
   },
   "outputs": [],
   "source": [
    "# Implementing ImageDataGenerator for data augmentation. This is a very good technique which reduces overfitting as it generates extra images by flipping, zooming e.t.c the images. This makes the model have more images to learn from.\n",
    "datagen = ImageDataGenerator ( horizontal_flip =True ,\n",
    "vertical_flip =True ,\n",
    "zoom_range =0.2,\n",
    "rotation_range =90 ,\n",
    "fill_mode ='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:34.300360Z",
     "iopub.status.busy": "2021-10-13T02:11:34.299906Z",
     "iopub.status.idle": "2021-10-13T02:11:34.310249Z",
     "shell.execute_reply": "2021-10-13T02:11:34.309134Z",
     "shell.execute_reply.started": "2021-10-13T02:11:34.300311Z"
    },
    "id": "6Zp5JL_9m1dR"
   },
   "outputs": [],
   "source": [
    "# Defining other parameters\n",
    "epochs=20 # An epoch is one complete pass through the training data, We specify 20 here\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001) # Defining our Adam optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:34.312400Z",
     "iopub.status.busy": "2021-10-13T02:11:34.311912Z",
     "iopub.status.idle": "2021-10-13T02:11:34.331006Z",
     "shell.execute_reply": "2021-10-13T02:11:34.330160Z",
     "shell.execute_reply.started": "2021-10-13T02:11:34.312356Z"
    },
    "id": "H4et8XNaIGuG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compiling our model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[fbeta])\n",
    "\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=2,\n",
    "                           verbose=0)]\n",
    "             \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:34.332860Z",
     "iopub.status.busy": "2021-10-13T02:11:34.332216Z",
     "iopub.status.idle": "2021-10-13T02:11:34.445998Z",
     "shell.execute_reply": "2021-10-13T02:11:34.444855Z",
     "shell.execute_reply.started": "2021-10-13T02:11:34.332815Z"
    },
    "id": "6UMb3cp6Ei39",
    "outputId": "4e1e1b00-4d70-4645-f7d0-2d2414bd34b6"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:11:34.448306Z",
     "iopub.status.busy": "2021-10-13T02:11:34.447879Z",
     "iopub.status.idle": "2021-10-13T02:12:32.610349Z",
     "shell.execute_reply": "2021-10-13T02:12:32.609601Z",
     "shell.execute_reply.started": "2021-10-13T02:11:34.448257Z"
    },
    "id": "-palcoJgEi4F",
    "outputId": "687be38c-d2fd-4fe8-8c5e-afe25349d453"
   },
   "outputs": [],
   "source": [
    "# We fit our model now. The code below fits the model while generating extra images due to the Imagedatagenerator and fitting them on the fly!\n",
    "model.fit_generator(datagen.flow(x_train,\n",
    "y_train,\n",
    "batch_size =32),\n",
    "steps_per_epoch =len(x_train)/32 ,\n",
    "validation_data = datagen.flow ( x_val,\n",
    "y_val,\n",
    "batch_size =32),\n",
    "validation_steps =len(x_val)/32 ,\n",
    "epochs =epochs ,\n",
    "callbacks = callbacks ,\n",
    "verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:12:32.613791Z",
     "iopub.status.busy": "2021-10-13T02:12:32.613524Z",
     "iopub.status.idle": "2021-10-13T02:12:32.763460Z",
     "shell.execute_reply": "2021-10-13T02:12:32.762507Z",
     "shell.execute_reply.started": "2021-10-13T02:12:32.613762Z"
    },
    "id": "fkO4OQ4SEi4M",
    "outputId": "ee4557fb-4880-4db1-dac8-bd0de07e570e"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:12:32.765442Z",
     "iopub.status.busy": "2021-10-13T02:12:32.764902Z",
     "iopub.status.idle": "2021-10-13T02:12:50.012177Z",
     "shell.execute_reply": "2021-10-13T02:12:50.011422Z",
     "shell.execute_reply.started": "2021-10-13T02:12:32.765401Z"
    },
    "id": "F2AzmNBwEi4R",
    "outputId": "e7322bca-aaf4-4297-ebad-5830797fe2c7"
   },
   "outputs": [],
   "source": [
    "test_1 =[]\n",
    "test_1.append (model.predict (x_test , batch_size = 128 , verbose =2) ) # We use the trained model for our test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:12:50.016008Z",
     "iopub.status.busy": "2021-10-13T02:12:50.015732Z",
     "iopub.status.idle": "2021-10-13T02:12:50.266554Z",
     "shell.execute_reply": "2021-10-13T02:12:50.265571Z",
     "shell.execute_reply.started": "2021-10-13T02:12:50.015979Z"
    },
    "id": "RnBndlAAEi4c",
    "outputId": "0abfad05-e779-4c5a-d51d-fa8e4a8e6cfd"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:12:50.268471Z",
     "iopub.status.busy": "2021-10-13T02:12:50.267934Z",
     "iopub.status.idle": "2021-10-13T02:12:50.275882Z",
     "shell.execute_reply": "2021-10-13T02:12:50.274896Z",
     "shell.execute_reply.started": "2021-10-13T02:12:50.268433Z"
    },
    "id": "Pycf5lJ8Ei4h"
   },
   "outputs": [],
   "source": [
    "# After prediction, we compile the results in a pandas dataframe \n",
    "result = np.array (test_1[0])\n",
    "for i in range (1,len(test_1) ):\n",
    " result += np. array (test_1)\n",
    "result = pd.DataFrame (result,columns = labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:12:50.277805Z",
     "iopub.status.busy": "2021-10-13T02:12:50.277270Z",
     "iopub.status.idle": "2021-10-13T02:12:50.306610Z",
     "shell.execute_reply": "2021-10-13T02:12:50.305625Z",
     "shell.execute_reply.started": "2021-10-13T02:12:50.277765Z"
    },
    "id": "PYmdqNNYEi4m"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:12:50.309155Z",
     "iopub.status.busy": "2021-10-13T02:12:50.308667Z",
     "iopub.status.idle": "2021-10-13T02:14:55.311981Z",
     "shell.execute_reply": "2021-10-13T02:14:55.311307Z",
     "shell.execute_reply.started": "2021-10-13T02:12:50.309110Z"
    },
    "id": "f47jHPOBEi4r",
    "outputId": "27fe888a-400f-4575-ec5f-25fbf90d01e9"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "    a = result.loc[[i]]\n",
    "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T02:14:55.314438Z",
     "iopub.status.busy": "2021-10-13T02:14:55.314047Z",
     "iopub.status.idle": "2021-10-13T02:14:55.825609Z",
     "shell.execute_reply": "2021-10-13T02:14:55.824757Z",
     "shell.execute_reply.started": "2021-10-13T02:14:55.314397Z"
    },
    "id": "U0gTYKxnEi4w",
    "outputId": "1d846bfe-0c04-43bc-9d32-4e769d39a855"
   },
   "outputs": [],
   "source": [
    "df_test_data['tags'] = preds\n",
    "df_test_data.to_csv('final_final_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
